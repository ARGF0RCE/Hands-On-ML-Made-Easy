{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71e023a8-ca2c-4ba1-9e50-eff553046c0d",
   "metadata": {},
   "source": [
    "# Chapter 5: Support Vector Machines\n",
    "\n",
    "A *Support Vector Machine* (SVM) is a powerful and versatile Machine Learning model capable of performing linear or nonlinear classification, regression, and even outlier detection. It is one of the most popular models in Machine Learning.\n",
    "\n",
    "SVMs are particualrly well suited for classification of complex small- or medium-sized datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51eb7eda-56d1-46cb-bb01-37853e7c60ab",
   "metadata": {},
   "source": [
    "## Linear SVM Classification\n",
    "\n",
    "The Fundamental idea behind SVMs is best explained with some pictures. Figure 5-1 shows part of the iris dataset that was introduced at the end of Chapter 4. The two classes can clearly be seperated with a straight line (they are *linearly seperable*). The left plot shows the decision boundaries of three linear classifiers. The model whose decision boundary is represented by the dashed line is so bad that it does not even seperate the classes properly. The other two models work perfectly on the training set, but their decision boundaries come so close to the instances that these models will probably not perform well on new instances. In contrast, the solid line in the plot on the right represents the decision boundary of an SVM classifier; this line not only seperates the two classes but also stays as far away from the closest training instances as possible. This is called *large margin classification*.\n",
    "\n",
    "<img src=\"Fig. 5-1.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508ca5e9-f208-43b6-a0b8-1c34d0b588c5",
   "metadata": {},
   "source": [
    "### Code for Linear SVM Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98878d94-0233-4d9a-b446-904df0fdd3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.4, 0.2],\n",
       "        [1.4, 0.2],\n",
       "        [1.3, 0.2],\n",
       "        [1.5, 0.2],\n",
       "        [1.4, 0.2],\n",
       "        [1.7, 0.4],\n",
       "        [1.4, 0.3],\n",
       "        [1.5, 0.2],\n",
       "        [1.4, 0.2],\n",
       "        [1.5, 0.1]]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris[\"data\"][:, (2, 3)] # Taking petal length, and petal width features only.\n",
    "y = (iris[\"target\"] == 2).astype(np.float64) # Considering only binary classification\n",
    "X[:10], y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bda8cb8-102c-4d2d-b39d-c413b0a1f203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('linear_svc', LinearSVC(C=1, loss='hinge'))])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the svm classifier pipeline\n",
    "svm_clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"linear_svc\", LinearSVC(C=1, loss=\"hinge\"))])\n",
    "\n",
    "svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "249c9758-5349-4e55-8a7e-c694a86802c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/Hands-On_ML_SKL_K_TF/.venvML/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('poly_features', PolynomialFeatures(degree=3)),\n",
       "                ('scaler', StandardScaler()),\n",
       "                ('svm_clf', LinearSVC(C=10, loss='hinge'))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X, y = make_moons(n_samples=100, noise=0.15)\n",
    "\n",
    "polynomial_svm_clf = Pipeline([\n",
    "    (\"poly_features\", PolynomialFeatures(degree=3)),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm_clf\", LinearSVC(C=10, loss=\"hinge\"))])\n",
    "\n",
    "polynomial_svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f37c5e-1fa4-48e9-a96f-1f929f851f14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
